{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 加载模型，导出ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model UNext\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import torch.onnx\n",
    "# project \n",
    "import sys \n",
    "sys.path.append(\"..\") \n",
    "import archs\n",
    "\n",
    "model_name = 'wrist'\n",
    "\n",
    "# Obtain your model, it can be also constructed in your script explicitly\n",
    "with open('../models/%s/config.yml' % model_name, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "print(\"=> creating model %s\" % config['arch'])\n",
    "model = archs.__dict__[config['arch']](config['num_classes'],\n",
    "                                       config['input_channels'],\n",
    "                                       config['deep_supervision'])\n",
    "\n",
    "model.load_state_dict(torch.load('../models/%s/model.pth' % config['name']))\n",
    "model.eval()\n",
    "# UNext input - 3 channels, 512x512,\n",
    "# values don't matter as we care about network structure.\n",
    "# But they can also be real inputs.\n",
    "dummy_input = torch.randn(1, 3, 512, 512, requires_grad=True)\n",
    "torch_out = model(dummy_input)\n",
    "\n",
    "# Invoke export\n",
    "torch.onnx.export(model, dummy_input, model_name + \".onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 检验 ONNX 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is valid!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "# 我们可以使用异常处理的方法进行检验\n",
    "try:\n",
    "    # 当我们的模型不可用时，将会报出异常\n",
    "    onnx.checker.check_model(\"wrist.onnx\")\n",
    "except onnx.checker.ValidationError as e:\n",
    "    print(\"The model is invalid: %s\"%e)\n",
    "else:\n",
    "    # 模型可用时，将不会报出异常，并会输出“The model is valid!”\n",
    "    print(\"The model is valid!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 使用 ONNX Runtime 进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"wrist.onnx\")\n",
    "\n",
    "# 将张量转化为ndarray格式\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# 构建输入的字典和计算输出结果\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(dummy_input)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# 比较使用PyTorch和ONNX Runtime得出的精度\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 进行实际预测并可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n",
      "(1, 1, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.core.composition import Compose\n",
    "\n",
    "# 读取图片\n",
    "img = cv2.imread('000002.png')\n",
    "# 对图片进行resize操作\n",
    "val_transform = Compose([\n",
    "    A.Resize(config['input_h'], config['input_w']),\n",
    "    A.Normalize(),\n",
    "])\n",
    "\n",
    "# image shape\n",
    "print(img.shape)\n",
    "img_h, img_w, _ = img.shape\n",
    "\n",
    "# preprocess img-[1,3,512,512]\n",
    "img = val_transform(image=img)['image']\n",
    "img = img.astype('float32') / 255\n",
    "img = img.transpose(2, 0, 1)\n",
    "img = torch.from_numpy(img).unsqueeze(0)\n",
    "# 构建输入的字典并将value转换位array格式\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "print(ort_outs[0].shape)\n",
    "img_out = ort_outs[0]\n",
    "img_out = Image.fromarray(np.uint8((img_out[0] * 255.0).clip(0, 255)[0]), mode='L')\n",
    "img_out.save('mask.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
